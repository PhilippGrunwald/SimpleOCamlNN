# SimpleOCamlNN

This project is still under development and not yet ready for use.

_SimpleOCamlNN_ will be a **minimalistic** (admittedly not really efficient) implementation of **fully connected feed forward neural networks** with **backpropagation** and **gradient descent**. Since the code is based only on an included self-written matrix library, and not on super complicated tensors optimised for multithreading and GPU usage with e.g. CUDA, the **code will be very easy to understand** and the principles of neural networks will be clear.

The project will be so lightweight that you can simply copy the code into your own project and it will run.

## References
1. Diederik P. Kingma, Jimmy Ba: *Adam: A Method for Stochastic Optimization* [Arxiv](https://arxiv.org/abs/1412.6980)

